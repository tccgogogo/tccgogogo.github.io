---
layout: post
title: "思维图(GoT)：让大模型突破思维链的极限"
subtitle:   "Graph of Thoughts: Solving Elaborate Problems with Large Language Models"
date:       2024-10-05 20:00:00
author:     "tiancc"
header-mask: 0.3
catalog:    true
tags:
    - RAG
    - COT
    - LLM
---
## 论文来源
今天分享的是苏黎世联邦理工学院、华沙理工大学和Cledar联合发表的一篇文章：思维图：用大语言模型解决复杂问题

**论文题目**：Graph of Thoughts: Solving Elaborate Problems with Large Language Models

**论文链接**：https://arxiv.org/pdf/2308.09687

**代码地址**：https://github.com/spcl/graph-of-thoughts

![](/img/GOT/paper.png)

## 论文概述

人类在进行思考时，不仅仅只遵循一条思维链，也不是像思维树那样尝试多种不同途径，而是会形成一个更加复杂的思维网。举个例子，一个人可能会先探索一条思维链，然后回溯再探索另一条，然后可能会意识到之前那条链的某个想法可以和当前链结合起来，取长补短，得到一个新的解决方案。类似地，大脑会形成复杂的网络，呈现出类似图的模式，比如循环模式。

这篇论文介绍了一种名为“思维图谱”（简称GoT）的框架，它通过将信息生成建模为任意图来增强大型语言模型的提示能力。在这个框架中，信息单元（即“LLM思考”）被视为顶点，而边对应于这些顶点之间的依赖关系。这种方法允许将任意的LLM思考结合起来，形成协同效应，提取整个思考网络的本质，或使用反馈循环增强思考。

## 论文核心

用户与LLM对话的过程主要包括用户消息（提示，prompts）和模型回复（思维、想法，thoughts），其中回复可以是一段文本（摘要任务）、一个文档（生成任务）或是一个代码块等。
为了充分激活语言模型的能力，通常会采用各种提示方法：
![](/img/GOT/frame.png)

- **输入到输出提示（Input-Output, IO）** ：输入序列后，直接用语言模型获取输出，不添加任何中间思考过程。
- **思维链（Chain-of-Thought, CoT）**：在输入和输出之间引入多个中间思维状态，相比IO方法，可以显著提升语言模型在数学难题和通用推理任务上的性能。
- **多思维链（Multiple CoTs）**：独立生成多条思维链，然后根据预先指定的评分指标返回最佳输出结果的思维链。
- **思维树（Tree of Thoughts, ToT）**：ToT将过程或推理建模为一棵思维树来增强CoT-SC方法，单个树节点代表部分解决方案；基于给定的节点，思维生成器（thought generator）可以构造出一定数量的新节点，然后用状态评估器（state evaluator）为每个新节点生成相应评分。

### 思维图（GOT）框架
GoT可以被建模为一个四元组(G, T, E, R)，其中G是“LLM推理过程”（即，上下文中的所有LLM思维及其关系），T是潜在的思维转换，E是用于获取思维得分的评估函数，R是用于选择最相关思维的排名函数。

LLM 的推理过程表示为（有向）图。该图中的每个节点对应于LLMs生成的单个想法，边代表想法之间的关系。也就是说，从思想a到b的边——或者图中的有向边 (a, b)——简单地告诉思想 b 是使用思想 a 作为输入生成的。与 ToT 提示类似，想法的确切定义取决于要解决的问题。更进一步，每个节点代表问题的（可能是中间的）解决方案，但我们可以在图中使用不同类型的节点来代表推理过程的不同方面（例如，计划与执行）。


![](/img/GOT/frame2.png)

- **提示器（Prompter）**：为LLM准备信息，主要负责把图结构编码进提示词中，GoT架构允许用户根据不同用例实现不同的图编码，提供全部图结构访问权限。
- **解析器（Parser）**：从LLM的回复中抽取信息，解析器为每个思维构造出一个思维状态（thought state），包含了抽取出的信息，并用于后续状态更新。
- **评分模块（Scoring）**：对LLM回复进行验证和评分，验证一个给定的LLM思维是否能够满足潜在的正确性条件，然后对思维进行打分。
- **控制器（Controller）**：协调整个推理过程，并决定如何继续推理，控制器中包含两个重要组件：**图操作**（the Graph of Operations, GoO）和**图推理状态**（GRS）。其中GoO是一个静态结构，指定了给定任务上的图分解过程，即规定了可用于LLM思维转换的操作，以及思维之间的顺序和依赖关系；每个操作对象都知道自己的前置操作和后继操作。GRS是一个动态结构，用来维护LLM推理过程进行中的状态，包括所有思维的历史及状态。

### 思维图（GOT）排序示例


![](/img/GOT/rerank.png)

使用到的操作包括：生成Generate、聚合Aggregate、评分Score、保留最优KeepBest。具体的prompt在论文中都有附录。

- **生成（Generate）操作**：将包含64个元素的输入数组分割成四个每个包含16个元素的块，只重复一次。
- **排序（sort)操作**：针对分割好的序列排序，k=3 表示对于每个包含16个元素的块，生成三种不同的排序结果。
- **评分（Score）**：为了获得评分，对于每一个数字0到9，计算输入数组与排序后的数组之间的差异，并将这10个值相加。差值为零表示已正确排序。
- **保留最优（KeepBest）**：保留最好的排序序列。
- **聚合（Aggregate）**：聚合成最终的序列。

## 论文实验

![](/img/GOT/result.png)
与现有技术相比，在对排序任务进行评估时，可以发现与 CoT 、具有自洽性的 CoT 或 ToT 提示等技术相比，GoT 提示始终产生更少的错误。


## 论文总结
提示工程是大型语言模型（LLM）研究的中心新领域之一。它使得能够高效地使用LLM，无需任何模型更新。然而，设计有效的提示是一项具有挑战性的任务。人类的任务解决通常是非线性的，它涉及将中间解决方案合并为最终解决方案，或在发现新见解时改变推理的流程。在这项工作中，提出了“思维图”（GoT），使LLM能够有效地解决不同的任务，而无需任何模型更新。其关键的想法是将LLM推理建模为一个任意图，其中思维是顶点，思维之间的依赖关系是边。这使得能够进行新的思维转换，如聚合。并且和现有提示方案相比，如ToT，图提示的排序质量和成本都是最优的。
